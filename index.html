<!DOCTYPE html>
<html>
<head>
    <title>Yilei Chen</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
          body {
            font-family: Roboto, 'sans-serif';
            font-size: 16px;
            background-color: #FFFFFF;
            color: #4F6071;
          }
          h1 {
              font-weight: 300;
              font-size: 2rem;
          }
          #header {
            background-color: #f4f4f4;
            /*background-color: #FFFFFF;*/
            display: flex;
            align-items: flex-end;
            padding-top:60px;
            padding-bottom:60px;
          }
          #footer {
            background-color: #FFFFFF;
            padding:60px;
          }
          #portrait {
            border: 3px solid white;
          }
          #header-text {
            margin-top: 60px;
            margin-left: 220px;
          }
          #header-text-name {
            font-size: 40px;
          }
          #header-text-title {
              font-size: 17px;
          }
          #header-text-affiliation {
              font-size: 17px;
              margin-top: 10px;
          }
          #header-text-email {
            margin-top: 10px;
            font-size: 17px;
            font-style: italic;
          }
          .header-text-desc {
            font-size: 20px;
          }
          .vspace-top {
            margin-top: 30px;
          }
          .vspace-top-news {
              margin-top: 15px;
          }
          .paper-image {
            width: 150px;
          }
          .news-date {
              font-weight: bold;
          }
          .paper-title {
            font-weight: bold;
          }
          .paper-authors {
            font-style: italic;
          }
    </style>
</head>

<body>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <div class="col-sm-3 offset-sm-1">
                    <img src='imgs/portrait.jpg' class='img-fluid' id='portrait'>
                </div>

                <div class="col">
                  <div id='header-text-name'>
                      Yilei Chen (陈亦雷)
                  </div>
		  <div id='header-text-title'>
                        Collaborative Ph.D. Student between Shanghai University and the University of Technology Sydney
                    </div>
                  <div id='header-text-email'>
                        yileichen (at) shu (dot) edu (dot cn)
                  </div>
                  <div>
                    <a href="https://github.com/yileichen96">[GitHub]</a>
                    <a href="https://scholar.google.com/citations?user=HYPiQyUAAAAJ&hl=zh-CN">[Google Scholar]</a>
                    <!-- <a href="https://linkedin.com/in/vincentsitzmann">[LinkedIn]</a> -->
                    <!-- <a href="docs/cv_vincent_sitzmann.pdf">[Download CV]</a> -->
                  </div>

                </div>
            </div>
        </div>
    </div>


    <div class='container'>
        <div class='row vspace-top'>
            <div class='col offset-sm-1'>
                <h1>Bio</h1>
                <p>
                    I'm currently working toward the collaborative Ph.D. degree between Shanghai University and the University of Technology Sydney.
		    Before that, I received my B.E. degree, in 2018, from the School of Communication and Information Engineering, Shanghai University, Shanghai, China. 
		    <br><br>
		    My research interests include light field/multi-view image processing. 
                </p>

                <div class='vspace-top'>
                    <h1>Publications</h1>
                </div>

                <!--- List of publications ---!>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/jacobian_fields_teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Disparity Enhancement-based Light Field Angular Super-Resolution
                        </div>
                        <div class='paper-desc'>
                            IEEE Signal Processing Letters 32, 81-85
                        </div>
                        <div class='paper-authors'>
                            Dongjun Cai, <b>Yilei Chen</b>, Xinpeng Huang, Ping An
                        </div>
                        <div>
                            <a href="https://sizhe-li.github.io/publication/neural_jacobian_field/">[Project page]</a>
                            <a href="https://github.com/sizhe-li/neural-jacobian-field">[Code]</a>
                            <a href="https://www.youtube.com/watch?v=dFZ1RvJMN7A&embeds_referring_euri=https%3A%2F%2Fsizhe-li.github.io%2F&source_ve_path=Mjg2NjY">[Video]</a>
                            <a href="https://arxiv.org/abs/2407.01392">[Paper]</a>
                            <a href="https://x.com/vincesitzmann/status/1821576713639510425">[Twitter Thread]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/diff_forcing_teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion
                        </div>
                        <div class='paper-desc'>
                            NeurIPS
                        </div>
                        <div class='paper-authors'>
                            Boyuan Chen*, Diego Marti Monso*, Yilun Du, Max Simchowitz, Russ Tedrake, Vincent Sitzmann
                        </div>
                        <div>
                            <a href="https://boyuan.space/diffusion-forcing/">[Project page]</a>
                            <a href="https://github.com/buoyancy99/diffusion-forcing">[Code]</a>
                            <a href="https://arxiv.org/abs/2407.01392">[Paper]</a>
                            <a href="https://x.com/BoyuanChen0/status/1808538170067407264">[Twitter Thread]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/niso_teaser.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Neural Isometries: Taming Transformations for Equivariant ML
                        </div>
                        <div class='paper-desc'>
                            NeurIPS
                        </div>
                        <div class='paper-authors'>
                            Tommy Mitchel, Michael Taylor, Vincent Sitzmann
                        </div>
                        <div>
                            <!-- <a href="https://github.com/buoyancy99/diffusion-forcing">[Code]</a> -->
                            <a href="https://arxiv.org/abs/2405.19296">[Paper]</a>
                            <a href="https://x.com/vincesitzmann/status/1801780132656324787">[Twitter Thread]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/flowmap_teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            FlowMap: High-Quality Camera Poses, Intrinsics, and Depth via Gradient Descent
                        </div>
                        <div class='paper-desc'>
                            arXiv
                        </div>
                        <div class='paper-authors'>
                            Cameron Smith*, David Charatan*, Ayush Tewari, Vincent Sitzmann
                        </div>
                        <div>
                            <a href="https://cameronosmith.github.io/flowmap/">[Project page]</a>
                            <a href="https://github.com/dcharatan/flowmap">[Code]</a>
                            <a href="https://arxiv.org/abs/2404.15259">[Paper]</a>
                            <a href="https://twitter.com/vincesitzmann/status/1783166394634575931">[Twitter Thread]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/pixelsplat_teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction
                        </div>
                        <div class='paper-desc'>
                            CVPR 2024 (Oral, Best Paper Runner-Up)
                        </div>
                        <div class='paper-authors'>
                            David Charatan, Sizhe Li, Andrea Tagliasacchi, Vincent Sitzmann
                        </div>
                        <div>
                            <a href="https://davidcharatan.com/pixelsplat/">[Project page]</a>
                            <a href="https://github.com/dcharatan/pixelsplat">[Code]</a>
                            <a href="https://arxiv.org/abs/2312.12337">[Paper]</a>
                            <a href="https://twitter.com/vincesitzmann/status/1737630706325409996">[Twitter Thread]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                       <img src='imgs/barycentric_coords.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Variational Barycentric Coordinates
                        </div>
                        <div class='paper-desc'>
                            SIGGRAPH Asia 2023 (Journal Track)
                        </div>
                        <div class='paper-authors'>
                            Ana Dodik, Oded Stein, Vincent Sitzmann, Justin Solomon
                        </div>
                        <div>
                            <a href="https://anadodik.github.io/publication/vbc/vbc.pdf">[Paper]</a>
                            <a href="https://twitter.com/ana_dodik/status/1722740042609877043">[Twitter Thread]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/diffusion_teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Diffusion with Forward Models: Solving Stochastic Inverse Problems Without Direct Supervision
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2024 (Spotlight)
                        </div>
                        <div class='paper-authors'>
                            Ayush Tewari*, Tianwei Yin*, George Cazenavette, Joshua B. Tenenbaum, Fredo Durand, William T. Freeman, <u>Vincent Sitzmann</u>
                        </div>
                        <div>
                            <a href="https://diffusion-with-forward-models.github.io/">[Project page]</a>
                            <a href="https://github.com/ayushtewari/DFM/">[Code]</a>
                            <a href="https://diffusion-with-forward-models.github.io/diffusion-forward-paper.pdf">[Paper]</a>
                            <a href="https://twitter.com/vincesitzmann/status/1695111279588037088">[Twitter Thread]</a>
                        </div>
                    </div>
                </div>


                <!--- next ---!>
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/flowcam_teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                             FlowCam: Training Generalizable 3D Radiance Fields without Camera Poses via Pixel-Aligned Scene Flow
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2024
                        </div>
                        <div class='paper-authors'>
                            Cameron Smith, Yilun Du, Ayush Tewari, Vincent Sitzmann
                        </div>
                        <div>
                            <a href="https://cameronosmith.github.io/flowcam/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2306.00180">[Paper]</a>
                            <a href="https://github.com/cameronosmith/FlowCam">[Code]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/stereo-view-synthesis-teaser.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Learning to Render Novel Views from Wide-Baseline Stereo Pairs
                        </div>
                        <div class='paper-desc'>
                            CVPR 2023
                        </div>
                        <div class='paper-authors'>
                            Yilun Du, Cameron Smith, Ayush Tewari†, Vincent Sitzmann†
                        </div>
                        <div>
                            <a href="https://yilundu.github.io/wide_baseline/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2304.08463">[Paper]</a>
                            <a href="https://github.com/yilundu/cross_attention_renderer">[Code]</a>
                            <a href="https://colab.research.google.com/drive/1PeL5oJ_eraLEdzTEVPLBwoM2pyv26WcU?usp=sharing">[Colab]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="groundplans/thumbnail.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Seeing 3D Objects in a Single Image via Self-Supervised Static-Dynamic Disentanglement
                        </div>
                        <div class='paper-desc'>
                            ICLR 2022
                        </div>
                        <div class='paper-authors'>
                            Prafull Sharma, Ayush Tewari, Yilun Du, Sergey Zakharov, Rares Ambrus, Adrien Gaidon,
                            William T. Freeman, Fredo Durand, Joshua B. Tenenbaum, <u>Vincent Sitzmann</u>
                        </div>
                        <div>
                            <a href="https://prafullsharma.net/see3d/">[Project page]</a>
                            <a href="https://prafullsharma.net/see3d/paper.pdf">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="feature-fields/thumbnail.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                             Decomposing NeRF for Editing via Feature Field Distillation
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2022
                        </div>
                        <div class='paper-authors'>
                            Sosuke Kobayashi, Eiichi Matsumoto, <u>Vincent Sitzmann</u>
                        </div>
                        <div>
                            <a href="https://pfnet-research.github.io/distilled-feature-fields/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2205.15585">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="ndfs/thumbnail.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation
                        </div>
                        <div class='paper-desc'>
                            ICRA 2022
                        </div>
                        <div class='paper-authors'>
                            Anthony Simeonov*, Yilun Du*, Andrea Tagliasacchi, Alberto Rodriguez, Pulkit Agrawal†, <u>Vincent Sitzmann</u>†
                        </div>
                        <div>
                            <a href="https://yilundu.github.io/ndf/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2112.05124">[Paper]</a>
                            <a href="https://github.com/anthonysimeonov/ndf_robot">[Code]</a>
                            <a href="https://colab.research.google.com/drive/16bFIFq_E8mnAVwZ_V2qQiKp4x4D0n1sG?usp=sharing">[Colab]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/gem_thumbnail.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Learning Signal-Agnostic Manifolds of Neural Fields
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2021
                        </div>
                        <div class='paper-authors'>
                            Yilun Du, Katherine M. Collins, Joshua Tenenbaum, <u>Vincent Sitzmann</u>
                        </div>
                        <div>
                            <a href="https://yilundu.github.io/gem/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2111.06387">[Paper]</a>
                            <a href="https://github.com/yilundu/gem">[Code]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="lfns/img/rooms_360_compressed.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2021 (Spotlight)
                        </div>
                        <div class='paper-authors'>
                            <u>Vincent Sitzmann</u>*, Semon Rezchikov*, William T. Freeman, Joshua B. Tenenbaum, Frédo Durand
                        </div>
                        <div>
                            <a href="https://vsitzmann.github.io/lfns">[Project page]</a>
                            <a href=" http://arxiv.org/abs/2106.02634">[Paper]</a>
                            <a href="https://github.com/vsitzmann/light-field-networks">[Code]</a>
<!--                            <a href="https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb">[Colab]</a>-->
                        </div>
                    </div>
                </div>

<!--                <div class='row vspace-top'>-->
<!--                    <div class="col-sm-3">-->
<!--                        <img src='imgs/deep_medial_fields.png' class='img-fluid'>-->
<!--                    </div>-->

<!--                    <div class="col">-->
<!--                        <div class='paper-title'>-->
<!--                            Deep Medial Fields-->
<!--                        </div>-->
<!--                        <div class='paper-desc'>-->
<!--                            arXiv-->
<!--                        </div>-->
<!--                        <div class='paper-authors'>-->
<!--                            Daniel Rebain, Ke Li, <u>Vincent Sitzmann</u>, Soroosh Yazdani, Kwang Moo Yi, Andrea Tagliasacchi-->
<!--                        </div>-->
<!--                        <div>-->
<!--                            <a href="https://arxiv.org/abs/2106.03804">[Paper]</a>-->
<!--                        </div>-->
<!--                    </div>-->
<!--                </div>-->

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="siren/img/poisson_convergence_15s_label.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Implicit Neural Representations with Periodic Activation Functions
                        </div>
                        <div class='paper-desc'>
			    NeurIPS 2020 (Oral)
                        </div>
                        <div class='paper-authors'>
                            <u>Vincent Sitzmann</u>*, Julien N. P. Martel*, Alexander W. Bergman, David B. Lindell, Gordon Wetzstein
                        </div>
                        <div>
                            <a href="https://vsitzmann.github.io/siren">[Project page]</a>
                            <a href="https://arxiv.org/abs/2006.09661">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="metasdf/img/metasdf_steps_comp.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            MetaSDF: Meta-learning Signed Distance Functions
                        </div>
                        <div class='paper-desc'>
                            NeurIPS 2020
                        </div>
                        <div class='paper-authors'>
                            <u>Vincent Sitzmann</u>*, Eric R. Chan*, Richard Tucker, Noah Snavely, Gordon Wetzstein
                        </div>
                        <div>
                            <a href="https://vsitzmann.github.io/metasdf">[Project page]</a>
                            <a href="https://github.com/vsitzmann/metasdf">[Code]</a>
                            <a href="https://arxiv.org/abs/2006.09662">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/star_img.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
			    State of the Art on Neural Rendering
                        </div>
                        <div class='paper-desc'>
				Computer Graphics Forum 2020 - EG 2020 (STAR Report)
                        </div>
                        <div class='paper-authors'>
                            Ayush Tewari*, Ohad Fried*, Justus Thies*, <u>Vincent Sitzmann*</u>, Stephen Lombardi, Kalyan Sunkavalli, Ricardo Martin-Brualla, Tomas Simon, Jason Saragih, Matthias Nießner, Rohit Pandey, Sean Fanello, Gordon Wetzstein, Jun-Yan Zhu, Christian Theobalt, Maneesh Agrawala, Eli Shechtman, Dan B Goldman, Michael Zollhöfer
                        </div>
                        <div>
                            <a href="https://arxiv.org/pdf/2004.03805.pdf">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/srn_seg_repimage.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
		            Inferring Semantic Information with 3D Neural Scene Representations
                        </div>
                        <div class='paper-desc'>
				3DV
                        </div>
                        <div class='paper-authors'>
                            Amit Kohli*, <u>Vincent Sitzmann*</u>, Gordon Wetzstein
                        </div>
                        <div>
                            <a href="https://www.computationalimaging.org/publications/semantic-srn/">[Project page]</a>
                            <a href="https://arxiv.org/pdf/2003.12673.pdf">[Preprint]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/SRNs.gif' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations
                        </div>
                        <div class='paper-desc'>
			    NeurIPS 2019 (Oral, <b>Honorable Mention "Outstanding New Directions"</b>)
                        </div>
                        <div class='paper-authors'>
                            <u>Vincent Sitzmann</u>, Michael Zollhöfer, Gordon Wetzstein
                        </div>
                        <div>
                            <a href="http://vsitzmann.github.io/srns/">[Project page]</a>
                            <a href="http://arxiv.org/abs/1906.01618">[Preprint]</a>
			    <a href="https://github.com/vsitzmann/scene-representation-networks">[Code]</a>
                        </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/deepvoxels.png' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          DeepVoxels: Learning Persistent 3D Feature Embeddings
                      </div>
                      <div class='paper-desc'>
		      CVPR 2019 (Oral)
                      </div>
                      <div class='paper-authors'>
                      <u>Vincent Sitzmann</u>, Justus Thies, Felix Heide, Matthias Nießner, Gordon Wetzstein, Michael Zollhöfer
                      </div>
                      <div>
                         <a href="http://vsitzmann.github.io/deepvoxels/">[Project page]</a>
                         <a href="https://arxiv.org/abs/1812.01024">[Paper]</a>
                         <a href="https://github.com/vsitzmann/deepvoxels">[Code]</a>
                      </div>
                    </div>
                </div>


                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/onn_thumbnail.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Hybrid optical-electronic convolutional neural networks with optimized diffractive optics for image classification
                      </div>
                      <div class='paper-desc'>
                        Scientific Reports
                      </div>
                      <div class='paper-authors'>
                      Julie Chang, <u>Vincent Sitzmann</u>, Xiong Dun, Wolfgang Heidrich, Gordon Wetzstein
                      </div>
                      <div>
                        <a href="https://www.nature.com/articles/s41598-018-30619-y">[Paper]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/end-to-end-cam.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          End-to-end Optimization of Optics and Image Processing for Achromatic Extended Depth of Field and Super-resolution Imaging
                      </div>
                      <div class='paper-desc'>
                          SIGGRAPH 2018
                      </div>
                      <div class='paper-authors'>
                          <u>Vincent Sitzmann*</u>, Steven Diamond*, Yifan Peng*, Xiong Dun, Stephen Boyd, Wolfgang Heidrich, Felix Heide, Gordon Wetzstein
                      </div>
                      <div>
                         <a href="https://vsitzmann.github.io/deepoptics/">[Project page]</a>
                         <a href="https://drive.google.com/file/d/1Xums2qyqSGP_z_24HnYpM9gbRm1_uAzY/view?usp=sharing">[Paper]</a>
                         <a href="https://github.com/vsitzmann/deepoptics">[Code]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/saliency.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                        Saliency in VR: How do people explore virtual environments?
                      </div>
                      <div class='paper-desc'>
                        IEEE VR 2018
                      </div>
                      <div class='paper-authors'>
                          <u>Vincent Sitzmann*</u>, Ana Serrano*, Amy Pavel, Maneesh Agrawala, Belen Masia, Diego Gutierrez, Gordon Wetzstein
                      </div>
                      <div>
                        <a href="https://vsitzmann.github.io/vr-saliency">[Project page]</a>
                        <a href="http://ieeexplore.ieee.org/document/8269807/">[Paper]</a>
                        <a href="https://www.github.com/vsitzmann/vr-saliency">[Code]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/cognitive_events.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Movie Editing and Cognitive Event Segmentation in Virtual Reality Video
                      </div>
                      <div class='paper-desc'>
                          SIGGRAPH 2017
                      </div>
                      <div class='paper-authors'>
                          Ana Serrano, <u>Vincent Sitzmann</u>, Jaime Ruiz-Borau, Gordon Wetzstein, Diego Gutierrez, Belen Masia
                      </div>
                      <div>
                        <a href="http://webdiis.unizar.es/~aserrano/docs/Serrano_SIGG2017_VR-cine.pdf">[Paper]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/sickness_prediction.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Towards a Machine-learning Approach for Sickness Prediction in 360° Stereoscopic Videos
                      </div>
                      <div class='paper-desc'>
                          IEEE VR 2018
                      </div>
                      <div class='paper-authors'>
                          Nitish Padmanaban*, Timon Ruban*, <u>Vincent Sitzmann</u>, Anthony M. Norcia, Gordon Wetzstein
                      </div>
                      <div>
                        <a href="http://ieeexplore.ieee.org/document/8267239/">[Paper]</a>
                      </div>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div id='footer' class='vspace-top'>
    <div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>
